{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### The Bag of Words (BoW) model is a simple and commonly used technique for text representation in Natural Language Processing (NLP). It represents text data as a set of words with their frequencies, disregarding the order of words. Below is a detailed implementation of the BoW model from scratch.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"class BagOfWords:\n    def __init__(self):\n        \"\"\"\n        Initialize the Bag of Words model.\n        \"\"\"\n        self.vocabulary = {}  # Dictionary to store the word-to-index mapping.\n        self.word_count = {}  # Dictionary to store the frequency of each word.\n\n    def fit(self, documents):\n        \"\"\"\n        Build the vocabulary and word count from the provided documents.\n        \n        Parameters:\n        documents (list of str): List of documents (strings) to build the vocabulary.\n        \"\"\"\n        word_set = set()  # Set to hold unique words.\n\n        # Iterate over each document\n        for doc in documents:\n            words = doc.split()  # Split document into words based on whitespace.\n            word_set.update(words)  # Update the set with words from the current document.\n\n        # Create a vocabulary mapping each unique word to an index\n        self.vocabulary = {word: idx for idx, word in enumerate(word_set)}\n\n        # Initialize the word count dictionary\n        self.word_count = {word: 0 for word in self.vocabulary}\n\n    def transform(self, documents):\n        \"\"\"\n        Convert documents into a Bag of Words representation.\n        \n        Parameters:\n        documents (list of str): List of documents (strings) to convert.\n        \n        Returns:\n        list of lists: Each inner list is a vector representing a document.\n        \"\"\"\n        rows = []  # List to store the BoW representation of each document.\n\n        # Iterate over each document\n        for doc in documents:\n            row = [0] * len(self.vocabulary)  # Initialize a zero vector for the current document.\n            words = doc.split()  # Split the document into words.\n            \n            # Count the frequency of each word in the document\n            for word in words:\n                if word in self.vocabulary:\n                    index = self.vocabulary[word]  # Get the index of the word from the vocabulary.\n                    row[index] += 1  # Increment the count for this word in the document's vector.\n            \n            rows.append(row)  # Append the vector representation of the document to the rows list.\n\n        return rows\n\n    def fit_transform(self, documents):\n        \"\"\"\n        Fit the model and transform the documents in one step.\n        \n        Parameters:\n        documents (list of str): List of documents (strings) to fit and transform.\n        \n        Returns:\n        list of lists: Each inner list is a vector representing a document.\n        \"\"\"\n        self.fit(documents)  # Build the vocabulary and word count from the documents.\n        return self.transform(documents)  # Convert the documents into BoW representation.","metadata":{"execution":{"iopub.status.busy":"2024-07-20T10:05:19.642651Z","iopub.execute_input":"2024-07-20T10:05:19.643535Z","iopub.status.idle":"2024-07-20T10:05:19.684296Z","shell.execute_reply.started":"2024-07-20T10:05:19.643497Z","shell.execute_reply":"2024-07-20T10:05:19.683027Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Example usage\nif __name__ == \"__main__\":\n    # Sample documents\n    documents = [\n        \"the cat sat on the mat\",\n        \"the dog ate my homework\",\n        \"the cat ate the dog food\"\n    ]\n\n    # Initialize the Bag of Words model\n    bow = BagOfWords()\n    \n    # Fit the model and transform the documents\n    bag_of_words = bow.fit_transform(documents)\n    \n    # Print the Bag of Words representation\n    print(\"Vocabulary:\", bow.vocabulary)\n    print(\"Bag of Words Representation:\")\n    for i, vector in enumerate(bag_of_words):\n        print(f\"Document {i + 1}: {vector}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T10:05:59.492151Z","iopub.execute_input":"2024-07-20T10:05:59.492539Z","iopub.status.idle":"2024-07-20T10:05:59.499991Z","shell.execute_reply.started":"2024-07-20T10:05:59.492508Z","shell.execute_reply":"2024-07-20T10:05:59.498574Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Vocabulary: {'cat': 0, 'my': 1, 'the': 2, 'on': 3, 'sat': 4, 'food': 5, 'homework': 6, 'mat': 7, 'dog': 8, 'ate': 9}\nBag of Words Representation:\nDocument 1: [1, 0, 2, 1, 1, 0, 0, 1, 0, 0]\nDocument 2: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1]\nDocument 3: [1, 0, 2, 0, 0, 1, 0, 0, 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Additional example usage\nif __name__ == \"__main__\":\n    # Sample documents\n    documents = [\n        \"I love programming in Python\",\n        \"Machine learning is fun\",\n        \"Python is a versatile language\",\n        \"Learning new skills is always beneficial\"\n    ]\n\n    # Initialize the Bag of Words model\n    bow = BagOfWords()\n    \n    # Fit the model and transform the documents\n    bag_of_words = bow.fit_transform(documents)\n    \n    # Print the Bag of Words representation\n    print(\"Vocabulary:\", bow.vocabulary)\n    print(\"Bag of Words Representation:\")\n    for i, vector in enumerate(bag_of_words):\n        print(f\"Document {i + 1}: {vector}\")\n\n    # More example documents with mixed content\n    more_documents = [\n        \"the quick brown fox jumps over the lazy dog\",\n        \"a journey of a thousand miles begins with a single step\",\n        \"to be or not to be that is the question\",\n        \"the rain in Spain stays mainly in the plain\",\n        \"all human beings are born free and equal in dignity and rights\"\n    ]\n\n    # Fit the model and transform the new set of documents\n    bow_more = BagOfWords()\n    bag_of_words_more = bow_more.fit_transform(more_documents)\n    \n    # Print the Bag of Words representation for the new documents\n    print(\"\\nVocabulary for new documents:\", bow_more.vocabulary)\n    print(\"Bag of Words Representation for new documents:\")\n    for i, vector in enumerate(bag_of_words_more):\n        print(f\"Document {i + 1}: {vector}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T10:06:11.525718Z","iopub.execute_input":"2024-07-20T10:06:11.526148Z","iopub.status.idle":"2024-07-20T10:06:11.535117Z","shell.execute_reply.started":"2024-07-20T10:06:11.526111Z","shell.execute_reply":"2024-07-20T10:06:11.533887Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Vocabulary: {'love': 0, 'learning': 1, 'Learning': 2, 'a': 3, 'beneficial': 4, 'new': 5, 'Machine': 6, 'fun': 7, 'always': 8, 'I': 9, 'language': 10, 'Python': 11, 'programming': 12, 'skills': 13, 'versatile': 14, 'is': 15, 'in': 16}\nBag of Words Representation:\nDocument 1: [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1]\nDocument 2: [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\nDocument 3: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0]\nDocument 4: [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n\nVocabulary for new documents: {'fox': 0, 'human': 1, 'and': 2, 'Spain': 3, 'all': 4, 'born': 5, 'over': 6, 'rain': 7, 'lazy': 8, 'dignity': 9, 'stays': 10, 'dog': 11, 'are': 12, 'jumps': 13, 'in': 14, 'that': 15, 'rights': 16, 'is': 17, 'begins': 18, 'to': 19, 'quick': 20, 'single': 21, 'a': 22, 'equal': 23, 'with': 24, 'mainly': 25, 'question': 26, 'not': 27, 'be': 28, 'miles': 29, 'brown': 30, 'thousand': 31, 'or': 32, 'beings': 33, 'free': 34, 'journey': 35, 'the': 36, 'step': 37, 'plain': 38, 'of': 39}\nBag of Words Representation for new documents:\nDocument 1: [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0]\nDocument 2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 3, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1]\nDocument 3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\nDocument 4: [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0]\nDocument 5: [0, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Explanation\n\n1. **Initialization (`__init__` Method):**\n   - `self.vocabulary` is a dictionary to store the mapping of each unique word to an index.\n   - `self.word_count` is a dictionary to keep track of the frequency of each word in the documents.\n\n2. **Fitting (`fit` Method):**\n   - `word_set` is used to gather all unique words from the documents.\n   - For each document, split it into words and update the `word_set`.\n   - Create the vocabulary dictionary where each unique word is assigned an index.\n   - Initialize `self.word_count` to store word frequencies.\n\n3. **Transforming (`transform` Method):**\n   - Convert each document into a vector based on the vocabulary.\n   - For each word in a document, increment the corresponding position in the vector based on the word's index.\n\n4. **Fit and Transform (`fit_transform` Method):**\n   - Combines `fit` and `transform` methods into one step.\n\n5. **Example Usage:**\n   - Create a list of sample documents.\n   - Initialize the `BagOfWords` object.\n   - Fit the model and transform the documents.\n   - Print the vocabulary and the Bag of Words representation for each document.\n\nThis implementation demonstrates the basic concept of the Bag of Words model. It converts text documents into numerical vectors based on word frequency, which can be used as input features for machine learning models.","metadata":{}}]}